AlgoExpert has the home page, code execution platform, purchases, etc. Are we going to design everything 
or the code execution engine only?

Only focus on the core code execution engine: User gets into the website, selects a question, solves it 
and marks itself as complete. Systems Expert and other products can also be skipped.

Since it is a paid product, there should be some level of availability but having said that, it is not 
a mission critical product, hence 8 hours to 2-3 days in a year downtime is reasonable, hence 2-3 9's
is fine.

We need focus on the latencies for the code execution engine. We need to try between 1-3 seconds of run 
code. 

Few Hundred thousands user will use the code execution engine every month and the scale should be such
that it is able to support 10K concurrent users at a given time.

The server should be available globally with US and India being the top two geographies.

Users should be able to save their code and data in the website. The home page will be a static page. 

The API has to be robust and there will be database which will store user related information which
will be pulled once the user logs in.

The design can be broken down into the following phases:
    - UI Static content:
        - Home Page will have Java Script Bundles
        - Can be stored in Blob Stores like GCS or S3
        - Content Delivery Network should be used to serve the static content both in India and the US, 
        ex. GC CDN or Cloud Flare can be used
        - A CDN load balancer to be used for load balancing the content based on the request from 
        region served
        - A path based Load Balancing will be set up in each region to satisfy individual function's
        requests
        -  Access Control List API service to handle core requests per users based on the Authorization.
        For example paid users will be shown all the videos but free users won't.
        - Static Questions list to be present in the GCS Bucket
        - If a User selects a Question, an ACL check is carried out and based on the check, the 
        question editor page is loaded
        - Client side caching of questions can be done in advance, so that the questions need not be 
        loaded from GCS bucket every time
        - Suppose there is 5000 bytes of data per language and if there are 10 languages, so it makes 
        50000 bytes per question and 50k*100 bytes = 5000000 = 5M bytes for 100 questions = 5 MBs
        - So caching of 5 MBs of data can be done without a problem.
        - 30 Mins of Eviction policy of browsed questions for users post log-in from cache 
        after which the questions will be reloaded from the GCS bucket
    - Auxilliary services like Payments, Authorization and Videos (to be skipped)
    - Core User actions: Seeing Questions, Writing code, seeing other users answers, etc
        - 
    - Running the Actual Code:
        - For User posted questions, it should be selected from PostgreSQL 
        - There can be Two separate activities:
            - Question Completion Status:
                - Every User to have 85 rows on a PosGres Table which will consist of the following
                fields:
                    - id (row number)
                    - uid (userid)
                    - qid (questionid)
                    - cStatus (completion status)
                - Since there will be many many users who might also be non paid users, and users
                will mark the completion status, there might be a lot of rows since there will be
                all the question rows for all the user, hence to speed up the query, we need to use an
                index on the uid

            - Question Solutions
                - Every user to have 85*7 rows, i.e. 85 questions and 7 languages in a postgress Table
                and will contain the following fields:
                    - id
                    - uid
                    - qid
                    - lang
                    - soln
                - Since Solutions will be filtered on user and questions, hence indexing to be done
                on both uid and qid
                - Incase the number of languages increases from 7 to say 20, then an additional indexing
                for language can be implemented so as to fix the performance issues
                - The Databases will be set up based on the regions and they will be updated with
                another asynchronously. For. Ex. US customers will hit the US database while
                India customers will use the India Database

    - While submitting the code, we need not think about the security problem. We only need to 
    worry about the Operating System
    - From the path based load balancer once user is logged in and submits the code into the server, 
    the server must handle rate limiting for users who might try to bring the platform down by 
    making a Denial of Service attack
    - Rate Limiting can be tier based, such that it is once per second, 3 times per 10 seconds and 
    a max of 5 times per minute
    - Rate Limiting can be accomplished with a Key-Value store like Redis
    - Once the Rate Limiting Server passes the user's code, separate bunch of servers can execute the
    code
    - A seperate load balancer can be set up to ensure a server which is already running an 
    execution, does not receive additional execution requests.
    - If there are 10k workers working on the code, then assuming a user hits the run button 
    3-4 times an hour, so there will be at the max 10-100 hits per second, so 10-100
    number of worker can suffice the code execution requests. 
    - The number of workers can scale horizontally as well as vertically
    - Logging and Monitoring as a bonus so that it can give us a suggestions on whether we must 
    add number of workers in the future.
