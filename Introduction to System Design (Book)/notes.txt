Scalability: It is the capability of a system, process or network to grow and manage increased demand. 
Any distributed system that can continously evolve to support the growing growing amount of work is considered
scalable.

Horizontal Scaling: It means that you scale by adding more servers into your pool of resources. Ex: Cassandra
and MongoDB

Vertical Scaling: vertical scaling means that you scale by adding more power (CPU, RAM, Storage, etc). Ex: MySQL

Reliability: A distributed system is considered reliable if it keeps delivering its services even when one or 
several of its software or hardware components fails. A distributed system achieves reliability through the
reducndancy of both the software components and data.

Availability: Availability is when a system remains operational to perform its required function in a specific
period. If a system is reliable, then it is available. However, if it is available, it is not necessarily 
reliable.

Two Standard measures of efficiency are:
    - Response Time (latency): Denotes the delay to obtain the first item.
    - Throughput (Bandwidth): Number of items delivered in a given unit (eg. a second) 

Serviceability or Manageability:  It is the simplicity and speed with which a system can be repaired or
maintained. Early detection of faults can decrease or avoid system downtime. 

Capacity Estimation and Constraints:
    - Traffic Estimates
    - Storage Estimates
    - Bandwidth Estimates
    - Memory Estimates

Incase we anticipate storing billions of rows, and we don't need to use relationships between objects, a 
NoSQL DB is a better choice. A NoSQL choice would also be easier to scale. 

Data Partition is requires to store information about billions of URLs. Partitioning can be carried out via:
    - Range Based Partition
    - Hash-Based Partition
    - Caching of frequently used data

When the Cache is full, and we want to replace a data which is the most recent one, we can chose the Least 
Recently Used (LRU) policy, where in we discard the discard the least recently used data first from the
cache memory.

A Load Balancing mechanism with the Round Robin approach takes out the server which is dead and stops 
sending any traffic. But a problem with Round Robin is that, it won't consider server load. Therefore if a 
server is overloaded or slow, the LB will not stop sending request to that server. Hence a more intelligent
solution is required.

In an App like Instagram, we need to create an index on the photoId, creationDate in the photo table, since 
we need to fetch recent images first.

We can plan to have dedicated servers for reads and different servers for writes so as to ensure that 
uploads don't hog the system.

Rather than keeping data by userID to create shards, we must create unique dataID and then place those 
dataID%100 in specific shards. When we do this, we do not place all the users data in a specific shard and
hence do not congest it incase the userId happens to be an Influencer.

A key generating DB can be a single point of failure. One work around could be defining two such databases, 
one generating even-numbered IDs and the other odd-numbered. Alternately we can implement a key generation
scheme.

